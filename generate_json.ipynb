{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_json.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IwtBjRQwOEhE",
        "JxRpQnEwRB3V",
        "CNQmcII0z1Ej",
        "M12zdZwykq5G",
        "Tt16TWzM5bR3",
        "LlsZGLAu6U1C",
        "vp4MWtzPOIUq",
        "HmTCOY9tSLHd",
        "1nn08m3ATJMW",
        "s4n1h3Kje-1O",
        "6whDZkEsf2Bb",
        "Wq1eLrv8dwye"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatiana-iazykova/2020_HACK_RUSSIANSUPERGLUE/blob/main/generate_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f5wl93tIuLt"
      },
      "source": [
        "%%capture\r\n",
        "!wget https://russiansuperglue.com/tasks/download\r\n",
        "!unzip download\r\n",
        "!rm download\r\n",
        "!rm -r /content/__MACOSX\r\n",
        "!rm -r sample_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9vbghmVGEJE"
      },
      "source": [
        "from pathlib import Path\n",
        "data_dir = Path(\"combined/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lPbpWjqF3t_",
        "outputId": "52b78c7e-6fd2-465e-9c7a-43246aed04a1"
      },
      "source": [
        "!wget -q --show-progress \"https://raw.githubusercontent.com/tatiana-iazykova/2020_HACK_RUSSIANSUPERGLUE/main/base.py\" -O base.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rbase.py               0%[                    ]       0  --.-KB/s               \rbase.py             100%[===================>]   3.44K  --.-KB/s    in 0s      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9h5aNHOJu4p"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "class JSONL_handler():\r\n",
        "    \"\"\" opens a jsonl file and turns it into a necessary data structure \"\"\"\r\n",
        "    \r\n",
        "    def __init__(self, path):\r\n",
        "        self.path = path # path to jsonl file\r\n",
        "\r\n",
        "    def to_pandas(self):\r\n",
        "        \"\"\" get jsonl file content as a pandas DataFrame\"\"\"\r\n",
        "        return pd.read_json(path_or_buf=self.path, lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwtBjRQwOEhE"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeikZ_jjGN2g"
      },
      "source": [
        "output_dir = Path(\"random_submission\")\n",
        "!mkdir $output_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiJ5Xvq7N9g5"
      },
      "source": [
        "output_dir_majority = Path(\"majority_submission\")\r\n",
        "!mkdir $output_dir_majority"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLUxyRPbOBQS"
      },
      "source": [
        "output_dir_random_weighted = Path(\"random_weighted_submission\")\r\n",
        "!mkdir $output_dir_random_weighted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7wP1Ix-LIjC"
      },
      "source": [
        "from base import BaseSolverSubmit\r\n",
        "import json\r\n",
        "\r\n",
        "class Random_submission():\r\n",
        "  def __init__(self, dataset, path = None, path_valid = None, path_test = None):\r\n",
        "    self.dataset = dataset\r\n",
        "    self.path = '/content/combined/' + dataset + '/train.jsonl' if path is None else path\r\n",
        "    self.path_valid = '/content/combined/' + dataset + '/val.jsonl' if path_valid is None else path_valid\r\n",
        "    self.path_test = '/content/combined/' + dataset + '/test.jsonl' if path_test is None else path_test\r\n",
        "\r\n",
        "  def test_output(self):\r\n",
        "    test = JSONL_handler(self.path_test).to_pandas()\r\n",
        "    test_pred = [{\"idx\": idx, \"label\": str(label).lower()} for idx, label in zip(test.idx, self.scores)]\r\n",
        "    return test_pred\r\n",
        "\r\n",
        "  def get_scores_random(self):\r\n",
        "    solver = BaseSolverSubmit(path = self.path, path_valid = self.path_valid, path_test = self.path_test)\r\n",
        "    self.scores = solver.random_choice(len(solver.valid))\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir / filename)\r\n",
        "  \r\n",
        "  def get_scores_majority(self):\r\n",
        "    solver = BaseSolverSubmit(path = self.path, path_valid = self.path_valid, path_test = self.path_test)\r\n",
        "    self.scores = solver.majority_class(len(solver.valid))\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir_majority / filename)\r\n",
        "\r\n",
        "  def get_scores_random_weighted(self):\r\n",
        "    solver = BaseSolverSubmit(path = self.path, path_valid = self.path_valid, path_test = self.path_test)\r\n",
        "    self.scores = solver.random_balanced_choice(len(solver.valid))\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir_random_weighted / filename)\r\n",
        "  \r\n",
        "  def save_output(self, data, path):\r\n",
        "    with open(path, mode=\"w\") as file:\r\n",
        "        for line in sorted(data, key=lambda x: int(x.get(\"idx\"))):\r\n",
        "            line[\"idx\"] = int(line[\"idx\"])\r\n",
        "            file.write(f\"{json.dumps(line, ensure_ascii=False)}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxRpQnEwRB3V"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThXAIyUtOSQa"
      },
      "source": [
        "### DaNetQA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1WEnl_hLCpj"
      },
      "source": [
        "random = Random_submission('DaNetQA')\r\n",
        "random.get_scores_random()\r\n",
        "majority.get_scores_majority()\r\n",
        "random_w.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4T64U3WOY8v"
      },
      "source": [
        "### RCB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03jeA6qjOhvP"
      },
      "source": [
        "random_RCB = Random_submission('RCB')\r\n",
        "random_RCB.get_scores_random()\r\n",
        "majority_RCB.get_scores_majority()\r\n",
        "random_w_RCB.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TinpaoG7Omcc"
      },
      "source": [
        "### PARus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkIhBzEOOpwy"
      },
      "source": [
        "random_PARus = Random_submission('PARus')\r\n",
        "random_PARus.get_scores_random()\r\n",
        "majority_PARus.get_scores_majority()\r\n",
        "random_w_PARus.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osXHWsymOwyw"
      },
      "source": [
        "### TERRa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wAPpm7bO2L2"
      },
      "source": [
        "random_TERRa = Random_submission('TERRa')\r\n",
        "random_TERRa.get_scores_random()\r\n",
        "majority_TERRa.get_scores_majority()\r\n",
        "random_w_TERRa.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VjhRf8cPGAC"
      },
      "source": [
        "### RUSSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7ztK2mLPKS6"
      },
      "source": [
        "random_RUSSE = Random_submission('RUSSE')\r\n",
        "random_RUSSE.get_scores_random()\r\n",
        "majority_RUSSE.get_scores_majority()\r\n",
        "random_w_RUSSE.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNBcUdxmlt1S"
      },
      "source": [
        "### RWSD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNYkV3sFltHo"
      },
      "source": [
        "random_RWSD = Random_submission('RWSD')\r\n",
        "random_RWSD.get_scores_random()\r\n",
        "majority_RWSD.get_scores_majority()\r\n",
        "random_w_RWSD.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRp4kZ2_r-5Q"
      },
      "source": [
        "### LidiRus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2COVBIBsCUS"
      },
      "source": [
        "random_LiDiRus = Random_submission('LiDiRus', path = '/content/combined/TERRa/train.jsonl', path_valid='/content/combined/TERRa/val.jsonl',\r\n",
        "                                   path_test = '/content/combined/LiDiRus/LiDiRus.jsonl')\r\n",
        "random_LiDiRus.get_scores_random()\r\n",
        "majority_LiDiRus.get_scores_majority()\r\n",
        "random_w_LiDiRus.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9ABK_4MzNEc"
      },
      "source": [
        "# Optimised Tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObReTtTAjIf5"
      },
      "source": [
        "output_dir_tfidf = Path(\"tfidf_submission\")\r\n",
        "!mkdir $output_dir_tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2nmmekl1Pmn"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.preprocessing import FunctionTransformer\r\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB0O0BSHxod8"
      },
      "source": [
        "%%capture\r\n",
        "# RSG baseline class for MuSeRC\r\n",
        "!pip3 install jsonlines\r\n",
        "!wget -q --show-progress \"https://github.com/RussianNLP/RussianSuperGLUE/raw/master/tfidf_baseline/MuSeRC.py\" -O MuSeRC.py\r\n",
        "!wget -q --show-progress \"https://github.com/RussianNLP/RussianSuperGLUE/raw/master/tfidf_baseline/RuCoS.py\" -O RuCoS.py\r\n",
        "import MuSeRC\r\n",
        "import RuCoS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1BH--9D0JS1"
      },
      "source": [
        "def unite(path1, path2):\r\n",
        "  df = JSONL_handler(path1).to_pandas()\r\n",
        "  df1 = JSONL_handler(path2).to_pandas()\r\n",
        "  return pd.concat([df, df1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEgnk8p61wiF"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "class Tfidf_Submisssion():\r\n",
        "  \r\n",
        "  def __init__(self, test, predictions, filename):\r\n",
        "    self.test = test\r\n",
        "    self.predictions = predictions\r\n",
        "    self.filename = filename + '.jsonl'\r\n",
        "\r\n",
        "  def test_output(self):\r\n",
        "    test_pred = [{\"idx\": idx, \"label\": str(label).lower()} for idx, label in zip(self.test.idx, self.predictions)]\r\n",
        "    self.save_output(test_pred, output_dir_tfidf / self.filename)\r\n",
        "\r\n",
        "  def save_output(self, data, path):\r\n",
        "    with open(path, mode=\"w\") as file:\r\n",
        "        for line in sorted(data, key=lambda x: int(x.get(\"idx\"))):\r\n",
        "            line[\"idx\"] = int(line[\"idx\"])\r\n",
        "            file.write(f\"{json.dumps(line, ensure_ascii=False)}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oEkw7s77sXK"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNQmcII0z1Ej"
      },
      "source": [
        "### RCB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVq5FEnUz4s8"
      },
      "source": [
        "RCB_train = unite('/content/combined/RCB/train.jsonl', '/content/combined/RCB/val.jsonl')\r\n",
        "RCB_test = JSONL_handler('/content/combined/RCB/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raUj6PU0zSn_"
      },
      "source": [
        "steps_RCB = [('tfidf', TfidfVectorizer(analyzer='word', max_features=10000)),\r\n",
        "          ('func', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)),\r\n",
        "         ('sgd', SGDClassifier(loss=\"log\", n_jobs=-1, alpha=0.00001, class_weight='balanced', random_state=42))]\r\n",
        "\r\n",
        "pipeline_RCB = Pipeline(steps_RCB)\r\n",
        "\r\n",
        "pipeline_RCB.fit(RCB_train.hypothesis, RCB_train.label)\r\n",
        "y_pred_RCB = pipeline_RCB.predict(RCB_test.hypothesis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsEEsUjf2Wtt"
      },
      "source": [
        "tfidf_rcb = Tfidf_Submisssion(RCB_test, y_pred_RCB, 'RCB')\r\n",
        "tfidf_rcb.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Verp9IAF5YQ"
      },
      "source": [
        "### RWSD\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRRn8CB0HNJG"
      },
      "source": [
        "class JSONL_handler_2():\r\n",
        "    \"\"\" opens a jsonl file and turns it into a necessary data structure \"\"\"\r\n",
        "    \r\n",
        "    def __init__(self, path):\r\n",
        "        self.path = path # path to jsonl file\r\n",
        "\r\n",
        "    def to_pandas(self):\r\n",
        "        \"\"\" get jsonl file content as a pandas DataFrame\"\"\"\r\n",
        "\r\n",
        "        data = self.read_jsonlines()\r\n",
        "\r\n",
        "        return pd.json_normalize(data).drop(columns=['idx'])\r\n",
        "\r\n",
        "    \r\n",
        "    def read_jsonlines(self):\r\n",
        "        \"\"\" yields json lines one by one \"\"\"\r\n",
        "        data = []\r\n",
        "        with open(self.path) as f:\r\n",
        "            for line in f:\r\n",
        "                data.append(json.loads(line))\r\n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3FRQXQoF9zk"
      },
      "source": [
        "RWSD_train = pd.concat([JSONL_handler_2('/content/combined/RWSD/train.jsonl').to_pandas(), JSONL_handler_2('/content/combined/RWSD/val.jsonl').to_pandas()])\r\n",
        "RWSD_test = JSONL_handler_2('/content/combined/RWSD/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpWRDVCXH5-w"
      },
      "source": [
        "RWSD_test_1 = JSONL_handler('/content/combined/RWSD/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhnA2AfcF-Lz"
      },
      "source": [
        "steps_RWSD  = [('tfidf', TfidfVectorizer(analyzer= 'char_wb',max_df= 0.8999999999999999, min_df=0.001, ngram_range=(1, 3))),\r\n",
        "         ('logreg', LogisticRegression( C = 1.01, class_weight='balanced'))]\r\n",
        "\r\n",
        "rwsd_tr = RWSD_train.assign(merged=lambda x: x['text'] + \"<sep>\" + x['target.span1_text'] + \"<sep>\" + x['target.span2_text'])\r\n",
        "rwsd_df = RWSD_test.assign(merged=lambda x: x['text'] + \"<sep>\" + x['target.span1_text'] + \"<sep>\" + x['target.span2_text'])\r\n",
        "\r\n",
        "pipeline_RWSD = Pipeline(steps_RWSD)\r\n",
        "\r\n",
        "pipeline_RWSD.fit(rwsd_tr.merged, rwsd_tr.label)\r\n",
        "y_pred_RWSD = pipeline_RWSD.predict(rwsd_df.merged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itHygNUJF-rl"
      },
      "source": [
        "tfidf_rwsd = Tfidf_Submisssion(RWSD_test_1, y_pred_RWSD, 'RWSD')\r\n",
        "tfidf_rwsd.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M12zdZwykq5G"
      },
      "source": [
        "### MuSeRC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFTjlG_K9s4o"
      },
      "source": [
        "train_path = \"combined/MuSeRC/train.jsonl\"\r\n",
        "val_path = \"combined/MuSeRC/val.jsonl\"\r\n",
        "test_path = \"combined/MuSeRC/test.jsonl\"\r\n",
        "\r\n",
        "muserc = JSONL_handler(train_path).to_pandas()\r\n",
        "\r\n",
        "def extract_passages(row):\r\n",
        "    return row.get('text')\r\n",
        "\r\n",
        "muserc['text'] = muserc['passage'].apply(extract_passages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceaQ4hiIktr6"
      },
      "source": [
        "%%capture\r\n",
        "# These parameters show the highest result during tryouts\r\n",
        "vect = TfidfVectorizer(ngram_range=(1, 3), analyzer='char_wb', max_df = 0.8, max_features=5000)\r\n",
        "# Trained on most passages only to use consine_similarity with question+asnwer pairs\r\n",
        "vect.fit(muserc.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onCTTygssNn1"
      },
      "source": [
        "_, MuSeRC_scores = MuSeRC.eval_MuSeRC(train_path, val_path, test_path, vect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtOxlITZC5tr"
      },
      "source": [
        "scores_MuSeRC = MuSeRC_scores[\"test_pred\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-FmUE9HslG8"
      },
      "source": [
        "tfidf_muserc = Tfidf_Submisssion(test_path, scores_MuSeRC, 'MuSeRC')\r\n",
        "tfidf_muserc.save_output(scores_MuSeRC, output_dir_tfidf / 'MuSeRC.jsonl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSiBxMySxZb8"
      },
      "source": [
        "### RuCos\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITXsN7mSJslO"
      },
      "source": [
        "class JSONL_handler_1():\r\n",
        "    \"\"\" opens a jsonl file and turns it into a necessary data structure \"\"\"\r\n",
        "    \r\n",
        "    def __init__(self, path):\r\n",
        "        self.path = path # path to jsonl file\r\n",
        "\r\n",
        "    def to_pandas(self):\r\n",
        "        \"\"\" get jsonl file content as a pandas DataFrame\"\"\"\r\n",
        "\r\n",
        "        text_df = pd.DataFrame(columns=['text', 'entities'])\r\n",
        "        questions_df = pd.DataFrame(columns=['text_id',\r\n",
        "                                             'question', 'answers'])\r\n",
        "\r\n",
        "        lines = self.yield_lines()\r\n",
        "\r\n",
        "        for passage_id, line in enumerate(lines):\r\n",
        "            text, entities, questions = self.split_text_and_questions(line)\r\n",
        "            text_df = text_df.append({'text':text, 'entities': entities}, \r\n",
        "                           ignore_index=True)\r\n",
        "            for i in range(len(questions)):\r\n",
        "                questions_df = questions_df.append({'text_id': passage_id,\r\n",
        "                                    'question': questions[i]['query'],\r\n",
        "                                     'answers': questions[i]['answers']},\r\n",
        "                                    ignore_index=True)\r\n",
        "        return text_df, questions_df\r\n",
        "\r\n",
        "    def yield_lines(self):\r\n",
        "        \"\"\" yields json lines one by one \"\"\"\r\n",
        "        with open(self.path) as f:\r\n",
        "            for line in f:\r\n",
        "                yield json.loads(line)\r\n",
        "\r\n",
        "\r\n",
        "    def split_text_and_questions(self, line):\r\n",
        "        \"\"\" transforms a complex json object into a single row dataframe\"\"\"\r\n",
        "        text = line['passage']['text']\r\n",
        "        entities = line['passage']['entities']\r\n",
        "        questions = line['qas']\r\n",
        "\r\n",
        "        return text, entities, questions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKQaf2ZDzNGR"
      },
      "source": [
        "train = JSONL_handler_1('/content/combined/RuCoS/train.jsonl')\r\n",
        "texts_train, questions_train = train.to_pandas()\r\n",
        "valid = JSONL_handler_1('/content/combined/RuCoS/val.jsonl')\r\n",
        "texts_valid, questions_valid = valid.to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2guLEeHx8Wp"
      },
      "source": [
        "train_path_RuCos = \"/content/combined/RuCoS/train.jsonl\"\r\n",
        "val_path_RuCos = \"/content/combined/RuCoS/val.jsonl\"\r\n",
        "test_path_RuCos = \"/content/combined/RuCoS/test.jsonl\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4L2C-PczLLY"
      },
      "source": [
        "def fill_entities(text, entities):\r\n",
        "    for entity in entities:\r\n",
        "        entity['text'] = text[entity['start']:entity['end']]\r\n",
        "\r\n",
        "for idx, row in texts_train.iterrows():\r\n",
        "    fill_entities(row.text, row.entities)\r\n",
        "\r\n",
        "for idx, row in texts_valid.iterrows():\r\n",
        "    fill_entities(row.text, row.entities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A10N7-06xups",
        "outputId": "08af3a90-45f1-41a8-df7a-a05baaec4b2f"
      },
      "source": [
        "vec1 = TfidfVectorizer(ngram_range=(1, 2), analyzer='char_wb', max_df = 0.95)\r\n",
        "vec1.fit(texts_train.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='char_wb', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=0.95, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jinnheiyC25"
      },
      "source": [
        "_, RuCoS_scores = RuCoS.eval_RuCoS(train_path_RuCos, val_path_RuCos, test_path_RuCos, vec1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "111VqpK0yNRu"
      },
      "source": [
        "scores_RuCoS = RuCoS_scores[\"test_pred\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRU6qx0uySYz"
      },
      "source": [
        "tfidf_rucos = Tfidf_Submisssion(test_path_RuCos, scores_RuCoS, 'RuCoS')\r\n",
        "tfidf_rucos.save_output(scores_RuCoS, output_dir_tfidf / 'RuCoS.jsonl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt16TWzM5bR3"
      },
      "source": [
        "### TERRa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdr7HuLi56CD"
      },
      "source": [
        "TERRa_train = unite('/content/combined/TERRa/train.jsonl', '/content/combined/TERRa/val.jsonl')\r\n",
        "TERRa_test = JSONL_handler('/content/combined/TERRa/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi87kVdr5dxY"
      },
      "source": [
        "steps_TERRa = [('countvect', CountVectorizer(min_df=15, max_df=0.4, lowercase=True, analyzer ='char_wb', decode_error = 'ignore', ngram_range = (2, 4))),\r\n",
        "         ('sgd', SGDClassifier(alpha = 1e-08, loss=\"log\", n_jobs=-1, class_weight='balanced', random_state=42))]\r\n",
        "\r\n",
        "pipeline_TERRa = Pipeline(steps_TERRa)\r\n",
        "\r\n",
        "pipeline_TERRa.fit(TERRa_train.hypothesis, TERRa_train.label)\r\n",
        "y_pred_TERRa = pipeline_TERRa.predict(TERRa_test.hypothesis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgfqX79x5_zE"
      },
      "source": [
        "tfidf_terra = Tfidf_Submisssion(TERRa_test, y_pred_TERRa, 'TERRa')\r\n",
        "tfidf_terra.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlsZGLAu6U1C"
      },
      "source": [
        "### DaNetQA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjj-SXgl6XpT"
      },
      "source": [
        "DaNetQA_train = unite('/content/combined/DaNetQA/train.jsonl', '/content/combined/DaNetQA/val.jsonl')\r\n",
        "DaNetQA_test = JSONL_handler('/content/combined/DaNetQA/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ90YD9a6aBY"
      },
      "source": [
        "steps_DaNetQA = [('vectorizer', TfidfVectorizer()),\r\n",
        "              ('sgd', SGDClassifier(loss=\"log\", n_jobs=-1, alpha=0.15, class_weight='balanced', random_state=42))]\r\n",
        "\r\n",
        "pipeline_DaNetQA = Pipeline(steps_DaNetQA)\r\n",
        "\r\n",
        "pipeline_DaNetQA.fit(DaNetQA_train.question, DaNetQA_train.label)\r\n",
        "y_pred_DaNetQA = pipeline_DaNetQA.predict(DaNetQA_test.question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3mG5sHj7TdO"
      },
      "source": [
        "tfidf_danetqa = Tfidf_Submisssion(DaNetQA_test, y_pred_DaNetQA, 'DaNetQa')\r\n",
        "tfidf_danetqa.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp4MWtzPOIUq"
      },
      "source": [
        "### RUSSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Z6EI5WOC_j"
      },
      "source": [
        "RUSSE_train = unite('/content/combined/RUSSE/train.jsonl', '/content/combined/RUSSE/val.jsonl')\r\n",
        "RUSSE_test = JSONL_handler('/content/combined/RUSSE/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgxB7dsrOSfc"
      },
      "source": [
        "def build_feature_RUSSE(row):\r\n",
        "    sentence1 = row[\"sentence1\"].strip()\r\n",
        "    sentence2 = row[\"sentence2\"].strip()\r\n",
        "    word = row[\"word\"].strip()\r\n",
        "    res = f\"{sentence1} {sentence2} {word}\"\r\n",
        "    return res\r\n",
        "\r\n",
        "train_concat = []\r\n",
        "for i, row in RUSSE_train.iterrows():\r\n",
        "    train_concat.append(build_feature_RUSSE(row))\r\n",
        "RUSSE_train['concatenated'] = train_concat\r\n",
        "\r\n",
        "valid_concat = []\r\n",
        "for i, row in RUSSE_test.iterrows():\r\n",
        "    valid_concat.append(build_feature_RUSSE(row))\r\n",
        "RUSSE_test['concatenated'] =  valid_concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BGlbWXjOg9Y"
      },
      "source": [
        "steps_RUSSE = [('tfidf', TfidfVectorizer(analyzer = 'word', max_df = 0.6, min_df= 0.001, ngram_range =  (1,2))),\r\n",
        "         ('logreg', LogisticRegression(C = 1.01, class_weight='balanced'))]\r\n",
        "\r\n",
        "pipeline_RUSSE = Pipeline(steps_RUSSE)\r\n",
        "\r\n",
        "pipeline_RUSSE.fit(RUSSE_train.concatenated, RUSSE_train.label)\r\n",
        "y_pred_RUSSE = pipeline_RUSSE.predict(RUSSE_test.concatenated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn4d1QvzPJBQ"
      },
      "source": [
        "tfidf_russe = Tfidf_Submisssion(RUSSE_test, y_pred_RUSSE, 'RUSSE')\r\n",
        "tfidf_russe.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmTCOY9tSLHd"
      },
      "source": [
        "### PARus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7QvfQzJSRYD"
      },
      "source": [
        "PARus_train = unite('/content/combined/PARus/train.jsonl', '/content/combined/PARus/val.jsonl')\r\n",
        "PARus_test = JSONL_handler('/content/combined/PARus/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3DMGV2OSKiM"
      },
      "source": [
        "def build_feature_PARus(row):\r\n",
        "    premise = str(row[\"premise\"]).strip()\r\n",
        "    choice1 = row[\"choice1\"]\r\n",
        "    choice2 = row[\"choice2\"]\r\n",
        "    label = row.get(\"label\")\r\n",
        "    question = \"Что было ПРИЧИНОЙ этого?\" if row[\"question\"] == \"cause\" else \"Что случилось в РЕЗУЛЬТАТЕ?\"\r\n",
        "    res = f\"{premise} {question} {choice1} {choice2}\"\r\n",
        "    return res\r\n",
        "\r\n",
        "\r\n",
        "train_concat = []\r\n",
        "for i, row in PARus_train.iterrows():\r\n",
        "    train_concat.append(build_feature_PARus(row))\r\n",
        "PARus_train['concatenated'] = train_concat\r\n",
        "\r\n",
        "valid_concat = []\r\n",
        "for i, row in PARus_test.iterrows():\r\n",
        "    valid_concat.append(build_feature_PARus(row))\r\n",
        "PARus_test['concatenated'] =  valid_concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_5yCz-aSdPw"
      },
      "source": [
        "steps_PARus = [('tfidf', TfidfVectorizer(analyzer= 'word', max_df= 0.6, min_df= 0.04, ngram_range= (1, 2))),\r\n",
        "         ('logreg', LogisticRegression(C = 1e-10, class_weight='balanced'))]\r\n",
        "\r\n",
        "pipeline_PARus = Pipeline(steps_PARus)\r\n",
        "\r\n",
        "pipeline_PARus.fit(PARus_train.concatenated, PARus_train.label)\r\n",
        "y_pred_PARus = pipeline_PARus.predict(PARus_test.concatenated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeXsS7HKS94r"
      },
      "source": [
        "tfidf_parus = Tfidf_Submisssion(PARus_test, y_pred_PARus, 'PARus')\r\n",
        "tfidf_parus.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nn08m3ATJMW"
      },
      "source": [
        "### LiDiRus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD2-ovnrTL60"
      },
      "source": [
        "LiDiRus_train = unite('/content/combined/TERRa/train.jsonl', '/content/combined/TERRa/val.jsonl').assign(merged=lambda x: x.premise + \"\\n\" + x.hypothesis)\r\n",
        "LiDiRus_test = JSONL_handler('/content/combined/LiDiRus/LiDiRus.jsonl').to_pandas().assign(merged=lambda x: x.sentence1 + \"\\n\" + x.sentence2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AhpFcZUVMMF"
      },
      "source": [
        "steps_LiDiRus = [('tfidf', TfidfVectorizer(analyzer= 'char_wb', max_df= 0.6, min_df=0.091, ngram_range = (1, 1))),\r\n",
        "         ('logreg', LogisticRegression(C = 1.01, class_weight='balanced'))]\r\n",
        "\r\n",
        "pipeline_LiDiRus = Pipeline(steps_LiDiRus)\r\n",
        "\r\n",
        "pipeline_LiDiRus.fit(LiDiRus_train.merged, LiDiRus_train.label)\r\n",
        "y_pred_LiDiRus = pipeline_LiDiRus.predict(LiDiRus_test.merged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBGa0LaKWHar"
      },
      "source": [
        "tfidf_lidirus = Tfidf_Submisssion(LiDiRus_test, y_pred_LiDiRus, 'LiDiRus')\r\n",
        "tfidf_lidirus.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4n1h3Kje-1O"
      },
      "source": [
        "# Heuristics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eudc_bvWfFOg"
      },
      "source": [
        "output_dir_heuristics_random = Path(\"heuristics_random_submission\")\r\n",
        "!mkdir $output_dir_heuristics_random\r\n",
        "output_dir_heuristics_majority = Path(\"heuristics_majority_submission\")\r\n",
        "!mkdir $output_dir_heuristics_majority\r\n",
        "output_dir_heuristics_rw = Path(\"heuristics_rw_submission\")\r\n",
        "!mkdir $output_dir_heuristics_rw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkrdG2dCfIOA"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "class Heuristic_submission():\r\n",
        "  def __init__(self, dataset, solver, path = None, path_valid = None, path_test = None):\r\n",
        "    self.dataset = dataset\r\n",
        "    self.path = '/content/combined/' + dataset + '/train.jsonl' if path is None else path\r\n",
        "    self.path_valid = '/content/combined/' + dataset + '/val.jsonl' if path_valid is None else path_valid\r\n",
        "    self.path_test = '/content/combined/' + dataset + '/test.jsonl' if path_test is None else path_test\r\n",
        "    self.solver = solver(path=self.path, path_valid= self.path_valid, path_test = self.path_test)\r\n",
        "\r\n",
        "  def test_output(self):\r\n",
        "    test = JSONL_handler(self.path_test).to_pandas()\r\n",
        "    test_pred = [{\"idx\": idx, \"label\": str(label).lower()} for idx, label in zip(test.idx, self.scores)]\r\n",
        "    return test_pred\r\n",
        "\r\n",
        "  def get_scores_random(self):\r\n",
        "    self.scores = self.solver.heuristics_all(final_decision=self.solver.random_choice)\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir_heuristics_random / filename)\r\n",
        "  \r\n",
        "  def get_scores_majority(self):\r\n",
        "    self.scores = self.solver.heuristics_all(final_decision=self.solver.majority_class)\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir_heuristics_majority / filename)\r\n",
        "\r\n",
        "  def get_scores_random_weighted(self):\r\n",
        "    self.scores = self.solver.heuristics_all(final_decision=self.solver.random_balanced_choice)\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir_heuristics_rw / filename)\r\n",
        "  \r\n",
        "  def save_output(self, data, path):\r\n",
        "    with open(path, mode=\"w\") as file:\r\n",
        "        for line in sorted(data, key=lambda x: int(x.get(\"idx\"))):\r\n",
        "            line[\"idx\"] = int(line[\"idx\"])\r\n",
        "            file.write(f\"{json.dumps(line, ensure_ascii=False)}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGYEsphefzxH"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ck9wn9ViCGQ"
      },
      "source": [
        "%%capture\r\n",
        "!pip install pymorphy2[fast]\r\n",
        "!pip install razdel\r\n",
        "!pip install natasha\r\n",
        "!pip3 install jsonlines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPL8k0EWwGEK"
      },
      "source": [
        "%%capture\r\n",
        "!wget \"https://github.com/RussianNLP/RussianSuperGLUE/raw/master/tfidf_baseline/LiDiRus.py\" -O LiDiRus.py\r\n",
        "!wget \"https://github.com/tatiana-iazykova/2020_HACK_RUSSIANSUPERGLUE/raw/main/utils.py\" -O utils.py\r\n",
        "!wget \"https://github.com/tatiana-iazykova/2020_HACK_RUSSIANSUPERGLUE/raw/main/Solvers/MuSeRCSolver.py\" -O MuSeRCSolver.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHI10Lurf5L2"
      },
      "source": [
        "import re\r\n",
        "from pymorphy2 import MorphAnalyzer\r\n",
        "import nltk\r\n",
        "from functools import lru_cache\r\n",
        "from base import BaseSolverSubmit\r\n",
        "from scipy import stats\r\n",
        "from string import punctuation\r\n",
        "from razdel import tokenize as razdel_tokenize\r\n",
        "from base import BaseSolver\r\n",
        "from utils import RSG_MorphAnalyzer\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "import jsonlines\r\n",
        "import numpy as np\r\n",
        "from collections import Counter\r\n",
        "import string\r\n",
        "import sys\r\n",
        "\r\n",
        "\r\n",
        "m = MorphAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6Ag7Ivq8gcw"
      },
      "source": [
        "import numpy as np\r\n",
        "from natasha import (\r\n",
        "    Segmenter,\r\n",
        "    MorphVocab,  \r\n",
        "    NewsEmbedding,\r\n",
        "    NewsMorphTagger,\r\n",
        "    Doc\r\n",
        ")\r\n",
        "\r\n",
        "segmenter = Segmenter()\r\n",
        "morph_vocab = MorphVocab()\r\n",
        "emb = NewsEmbedding()\r\n",
        "morph_tagger = NewsMorphTagger(emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XefdfnmSkEXj"
      },
      "source": [
        "import json\r\n",
        "def save_output(data, path):\r\n",
        "    with open(path, mode=\"w\") as file:\r\n",
        "        for line in sorted(data, key=lambda x: int(x.get(\"idx\"))):\r\n",
        "            line[\"idx\"] = int(line[\"idx\"])\r\n",
        "            file.write(f\"{json.dumps(line, ensure_ascii=False)}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6whDZkEsf2Bb"
      },
      "source": [
        "### TERRa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ-vKqCMf9Kx"
      },
      "source": [
        "class TERRaSolver(BaseSolverSubmit):\r\n",
        "   \r\n",
        "    def __init__(self, path: str, path_valid=None, path_test=None):\r\n",
        "        super(TERRaSolver, self).__init__(path, path_test, path_valid)\r\n",
        "   \r\n",
        "    def preprocess(self, columns):\r\n",
        "      for column in columns:\r\n",
        "        self.train[f\"{column}_lemmas\"] = self.train[column].apply(self.clean_text)\r\n",
        "        self.valid[f\"{column}_lemmas\"] = self.valid[column].apply(self.clean_text)\r\n",
        " \r\n",
        "    def words_only(self, text):\r\n",
        "      rg = re.compile(\"[А-Яа-яA-z]+\")\r\n",
        "      try:\r\n",
        "        return rg.findall(text.lower())\r\n",
        "      except:\r\n",
        "        return []\r\n",
        "\r\n",
        "    @lru_cache(maxsize=128)\r\n",
        "    def lemmatize_word(self, token, pymorphy=m):\r\n",
        "      return pymorphy.parse(token)[0].normal_form\r\n",
        "\r\n",
        "    def lemmatize_text(self, text):\r\n",
        "      return [self.lemmatize_word(w) for w in text]\r\n",
        "\r\n",
        "    def clean_text(self, text):\r\n",
        "      tokens = self.words_only(text)\r\n",
        "      lemmas = self.lemmatize_text(tokens)  \r\n",
        "      return lemmas\r\n",
        "    \r\n",
        "    def heuristics_all(self, final_decision=None):\r\n",
        "        y_pred = []\r\n",
        "        self.preprocess(columns=['premise', \"hypothesis\"])\r\n",
        "\r\n",
        "        for i, row in self.valid.iterrows():\r\n",
        "          \r\n",
        "          hyp = row.hypothesis.lower()\r\n",
        "          hyp_lem = set(row['hypothesis_lemmas'])\r\n",
        "          prem_lem = set(row['premise_lemmas'])\r\n",
        "          indic_non_ent = set(['только', 'мужчина'])\r\n",
        "\r\n",
        "          if hyp in row['premise'].lower():\r\n",
        "             y_pred.append('entailment')\r\n",
        "          elif len(prem_lem & hyp_lem)/len(hyp_lem) <= 1/3 or len(row['premise'].split()) < 29 or len(indic_non_ent & hyp_lem) > 0:\r\n",
        "            y_pred.append('not_entailment')\r\n",
        "          elif len(prem_lem & hyp_lem)/len(hyp_lem) == 0.75 or len(prem_lem & hyp_lem)/len(hyp_lem) == 1 or len(prem_lem & hyp_lem)/len(hyp_lem) == 2/3:\r\n",
        "            y_pred.append('entailment')\r\n",
        "          elif len(row['premise'].split()) > 32:\r\n",
        "            y_pred.append('entailment')\r\n",
        "          else:\r\n",
        "            y_pred.append(final_decision(test_size=1)[0])\r\n",
        "        \r\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNxAWwYxxlfZ"
      },
      "source": [
        "terra_heuristics = Heuristic_submission('TERRa', TERRaSolver)\r\n",
        "terra_heuristics.get_scores_random()\r\n",
        "terra_heuristics.get_scores_majority()\r\n",
        "terra_heuristics.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJSjaVPI62kX"
      },
      "source": [
        "### DaNetQA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPU9TbPG66nu"
      },
      "source": [
        "class DaNetQASolver(BaseSolverSubmit):\r\n",
        "    \r\n",
        "    def __init__(self, path: str, path_valid=None, path_test=None):\r\n",
        "        super(DaNetQASolver, self).__init__(path, path_test, path_valid)\r\n",
        "   \r\n",
        "    def heuristics_all(self, final_decision=None):\r\n",
        "        y_pred = []\r\n",
        "\r\n",
        "        for i, row in self.valid.iterrows():\r\n",
        "\r\n",
        "            question = row.question.lower()\r\n",
        "            question_w_count = len(question.split())\r\n",
        "            passage_w_count = len(row.passage.split())\r\n",
        "\r\n",
        "            if re.search(\"был|(^есть)\", question):\r\n",
        "              y_pred.append(True)\r\n",
        "            elif re.search(\"^входит|едят|правда ли\", question):\r\n",
        "              y_pred.append(False)\r\n",
        "            elif question_w_count > 5:\r\n",
        "              y_pred.append(False)\r\n",
        "            elif passage_w_count >= 90:\r\n",
        "              y_pred.append(False)\r\n",
        "            else:\r\n",
        "              y_pred.append(final_decision(test_size=1)[0])\r\n",
        "      \r\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJrSBwrU7R6U"
      },
      "source": [
        "danetqa_heuristics = Heuristic_submission('DaNetQA', DaNetQASolver)\r\n",
        "danetqa_heuristics.get_scores_random()\r\n",
        "danetqa_heuristics.get_scores_majority()\r\n",
        "danetqa_heuristics.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFkkBWKb7s0_"
      },
      "source": [
        "### RCB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB_hgyyy7v9o"
      },
      "source": [
        "class RCBSolver(BaseSolverSubmit):\r\n",
        "\r\n",
        "    def __init__(self, path: str, path_valid=None, path_test=None):\r\n",
        "        super(RCBSolver, self).__init__(path, path_test, path_valid)\r\n",
        "   \r\n",
        "    def preprocess(self, columns):\r\n",
        "      for column in columns:\r\n",
        "        self.train[f\"{column}_lemmas\"] = self.train[column].apply(self.clean_text)\r\n",
        "        self.valid[f\"{column}_lemmas\"] = self.valid[column].apply(self.clean_text)\r\n",
        " \r\n",
        "    def words_only(self, text):\r\n",
        "      rg = re.compile(\"[А-Яа-яA-z]+\")\r\n",
        "      try:\r\n",
        "        return rg.findall(text.lower())\r\n",
        "      except:\r\n",
        "        return []\r\n",
        "\r\n",
        "    @lru_cache(maxsize=128)\r\n",
        "    def lemmatize_word(self, token, pymorphy=m):\r\n",
        "      return pymorphy.parse(token)[0].normal_form\r\n",
        "\r\n",
        "    def lemmatize_text(self, text):\r\n",
        "      return [self.lemmatize_word(w) for w in text]\r\n",
        "\r\n",
        "    def clean_text(self, text):\r\n",
        "      tokens = self.words_only(text)\r\n",
        "      lemmas = self.lemmatize_text(tokens)  \r\n",
        "      return lemmas\r\n",
        "    \r\n",
        "    def heuristics_all(self, final_decision=None):\r\n",
        "        y_pred = []\r\n",
        "        self.preprocess(columns=['premise', \"hypothesis\"])\r\n",
        "\r\n",
        "        for i, row in self.valid.iterrows():\r\n",
        "          \r\n",
        "          hyp = row.hypothesis.lower()\r\n",
        "          hyp_lem = set(row['hypothesis_lemmas'])\r\n",
        "          prem_lem = set(row['premise_lemmas'])\r\n",
        "          indic_neutral = set(['подозревать', 'cчитать', 'говорить', 'думать', 'надеяться', 'понять', 'уверять'])\r\n",
        "          indic_ent = set(['признать'])\r\n",
        "\r\n",
        "          if hyp in row['premise'].lower() and len(indic_ent & prem_lem) > 0 :\r\n",
        "             y_pred.append('entailment')\r\n",
        "          elif len(prem_lem & hyp_lem)/len(hyp_lem) == 0.6:\r\n",
        "            y_pred.append('entailment')\r\n",
        "          elif len(indic_neutral & prem_lem) > 0:\r\n",
        "            y_pred.append('neutral')\r\n",
        "          elif len(row.hypothesis.split()) < 4:\r\n",
        "            y_pred.append('contradiction')\r\n",
        "          elif len(row.hypothesis.split()) >= 5 and len(row.hypothesis.split()) <= 7:\r\n",
        "            y_pred.append('neutral')\r\n",
        "          elif len(row['premise'].split()) > 15:\r\n",
        "            y_pred.append('entailment')\r\n",
        "          else:\r\n",
        "            y_pred.append(final_decision(test_size=1)[0])\r\n",
        "        \r\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHR8UdQR7wUj"
      },
      "source": [
        "rcb_heuristics = Heuristic_submission('RCB', RCBSolver)\r\n",
        "rcb_heuristics.get_scores_random()\r\n",
        "rcb_heuristics.get_scores_majority()\r\n",
        "rcb_heuristics.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8UVEo188Sz6"
      },
      "source": [
        "### PARus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PygoCcV8ZUc"
      },
      "source": [
        "class ParusSolver(BaseSolverSubmit):\r\n",
        "   \r\n",
        "    def __init__(self, path: str, path_valid=None, path_test=None):\r\n",
        "        super(ParusSolver, self).__init__(path, path_test, path_valid)\r\n",
        "   \r\n",
        "    def preprocess(self, columns):\r\n",
        "\r\n",
        "        for column in columns:\r\n",
        "            self.train[f\"{column}_lemmas\"] = self.train[column].apply(self.lemmatize)\r\n",
        "            self.valid[f\"{column}_lemmas\"] = self.valid[column].apply(self.lemmatize)\r\n",
        "\r\n",
        "    def lemmatize(self, text):\r\n",
        "        \"\"\"\r\n",
        "        param text: str\r\n",
        "        return: List of lemmas (strings)\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        doc = Doc(text)\r\n",
        "        doc.segment(segmenter)\r\n",
        "        doc.tag_morph(morph_tagger)\r\n",
        "\r\n",
        "        for token in doc.tokens:\r\n",
        "            token.lemmatize(morph_vocab)\r\n",
        "        lemmas = [token.lemma for token in doc.tokens]\r\n",
        "        return lemmas\r\n",
        "\r\n",
        "    \r\n",
        "    def heuristics_all(self, final_decision=None):\r\n",
        "        \"\"\"\r\n",
        "        This heruistic chooses the option that has more common lemmas with premise\r\n",
        "        If the amount of common words is equal for both choices, it uses {final_desicion}\r\n",
        "        function (one of BaseSolver functions) to predict\r\n",
        "        param: final_decision (function)\r\n",
        "        \"\"\"\r\n",
        "        y_pred = []\r\n",
        "        self.preprocess(columns=['premise', 'choice1', 'choice2'])\r\n",
        "\r\n",
        "        for i, row in self.valid.iterrows():\r\n",
        "            words1 = set(row.choice1_lemmas)\r\n",
        "            words2 = set(row.choice2_lemmas)\r\n",
        "            premise = set(row.premise_lemmas)\r\n",
        "            overlap1 = len(premise & words1)\r\n",
        "            overlap2 = len(premise & words2)\r\n",
        "            if overlap1 > overlap2:\r\n",
        "                y_pred.append(0)\r\n",
        "            elif overlap2 > overlap1:\r\n",
        "                y_pred.append(1)\r\n",
        "            else:\r\n",
        "                y_pred.append(final_decision(test_size=1)[0])\r\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY95BGQm80DP"
      },
      "source": [
        "parus_heuristics = Heuristic_submission('PARus', ParusSolver)\r\n",
        "parus_heuristics.get_scores_random()\r\n",
        "parus_heuristics.get_scores_majority()\r\n",
        "parus_heuristics.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZWlrntBdNz3"
      },
      "source": [
        "### RUSSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbHYMb8DdNY_"
      },
      "source": [
        "class RusseSolver(BaseSolverSubmit):\r\n",
        "\r\n",
        "    def __init__(self, path: str, path_valid=None, path_test=None):\r\n",
        "        super(RusseSolver, self).__init__(path, path_test, path_valid)\r\n",
        "\r\n",
        "    def heuristics_all(self, final_decision=None):\r\n",
        "        y_pred = []\r\n",
        "\r\n",
        "        for i, row in self.valid.iterrows():\r\n",
        "            tokens1 = set(row.sentence1.split())\r\n",
        "            tokens2 = set(row.sentence2.split())\r\n",
        "\r\n",
        "            if len(tokens1 & tokens2) / len(tokens1 | tokens2) > 0.10:\r\n",
        "                y_pred.append(True)\r\n",
        "            else:\r\n",
        "                options = np.array([final_decision(test_size=1)[0] for i in range(0,3)])\r\n",
        "                y_pred.append(stats.mode(options)[0][0])\r\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_OJeqwCqu3s"
      },
      "source": [
        "russe_heuristics = Heuristic_submission('RUSSE', RusseSolver)\r\n",
        "russe_heuristics.get_scores_random()\r\n",
        "russe_heuristics.get_scores_majority()\r\n",
        "russe_heuristics.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPyV7M0Ckv0C"
      },
      "source": [
        "### LiDiRus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGfQ0NDGkw0k"
      },
      "source": [
        "class LiDiRusSolver(BaseSolver):\r\n",
        "\r\n",
        "    def __init__(self, path: str, path_valid=None):\r\n",
        "        self.e_words = {\"чтобы\", 'будет', \"от\", \"он\"} # -> entailment\r\n",
        "        self.ne_words = {'и', \"не\", \"никогда\", \"вовсе\", 'что', \"это\"} # -> not_eintailment\r\n",
        "        self.morph = RSG_MorphAnalyzer() # PyMorphy + cashing\r\n",
        "        super(LiDiRusSolver, self).__init__(path, path_valid)\r\n",
        "\r\n",
        "    def preprocess(self):\r\n",
        "        self.cashe = {} # create a dictionary for lemmas\r\n",
        "        \"\"\" preprocess sentences to apply heuristics\"\"\"\r\n",
        "        self.valid[\"sentence1_words\"] = self.valid['sentence1'].str.split()\r\n",
        "        self.valid[\"sentence2_words\"] = self.valid['sentence2'].str.split()\r\n",
        "        self.valid[\"sentence1_lemmas\"] = self.morph.lemmantize_sentences(self.valid.sentence1.to_list())\r\n",
        "        self.valid[\"sentence2_lemmas\"] = self.morph.lemmantize_sentences(self.valid.sentence2.to_list())\r\n",
        "\r\n",
        "    def get_heuristics(self, non_intersect, intersect, non_intersect_lemmas, heuristic) -> dict:\r\n",
        "        \"\"\" all heuristics at once or one of them \"\"\"\r\n",
        "\r\n",
        "        heuristics = {\r\n",
        "            \"not_entailment\": {\r\n",
        "                \"little overlap\": len(non_intersect) > 10,\r\n",
        "\r\n",
        "                # catches if there is an extra clause inside\r\n",
        "                \"extra clause\": len(re.findall(r\",\", \" \".join(non_intersect))) > 1,\r\n",
        "\r\n",
        "                \"keyword\": len(non_intersect) == 2,\r\n",
        "\r\n",
        "                # negated word, e.g: необычный, незапланированно\r\n",
        "                # \"negated words\": re.search(r'(?<=\\s)не\\w+', \" \".join(non_intersect)) != None ,\r\n",
        "\r\n",
        "                # has one of the words from the list\r\n",
        "                \"wordlist\": len(self.ne_words.intersection(non_intersect)) > 0},\r\n",
        "\r\n",
        "            \"entailment\": {\r\n",
        "                \"all lemmas overlap\": len(non_intersect_lemmas) == 0,\r\n",
        "\r\n",
        "                \"wordlist\": len(self.e_words.intersection(intersect)) > 0}}\r\n",
        "\r\n",
        "        if heuristic != None:\r\n",
        "            # return a single heuristic only\r\n",
        "            key = list(heuristic.keys())[0]\r\n",
        "            value = heuristic[key]\r\n",
        "\r\n",
        "            return ({\r\n",
        "                key: { # key = \"entailment\" or \"not_entailment\"\r\n",
        "                      value: heuristics[key][value] # \"heuristic name\": Boolean\r\n",
        "                      }\r\n",
        "                    })\r\n",
        "        return (heuristics)\r\n",
        "\r\n",
        "    def heuristics_all(self, final_decision = None, heuristic = None):\r\n",
        "        \"\"\"\r\n",
        "            apply heuristics to a dataset\r\n",
        "            To check on a single heursitic, pass\r\n",
        "                        heuristic = {\"label\": \"heuristic name\"}\r\n",
        "            to this function\r\n",
        "        \"\"\"\r\n",
        "        y_pred = []\r\n",
        "\r\n",
        "\r\n",
        "        for i, row in self.valid.iterrows():\r\n",
        "\r\n",
        "            sentence1 = row['sentence1_words']\r\n",
        "            sentence2 = row['sentence2_words']\r\n",
        "\r\n",
        "            non_intersect = set(sentence1) ^ set(sentence2)\r\n",
        "            intersect = set(sentence1).intersection(sentence2)\r\n",
        "            lemmas_non_intersect = set(row.sentence1_lemmas) ^ set(row.sentence2_lemmas)\r\n",
        "\r\n",
        "            heuristics = self.get_heuristics(non_intersect,\r\n",
        "                                             intersect,\r\n",
        "                                             lemmas_non_intersect,\r\n",
        "                                             heuristic)\r\n",
        "\r\n",
        "\r\n",
        "            if ('entailment' in heuristics.keys() and\r\n",
        "                (True in list(heuristics['entailment'].values()))):\r\n",
        "                    y_pred.append('entailment')\r\n",
        "            elif ('not_entailment' in heuristics.keys() and\r\n",
        "                (True in list(heuristics['not_entailment'].values()))):\r\n",
        "                y_pred.append('not_entailment') # inserts an opposite label\r\n",
        "            else:\r\n",
        "                y_pred.append(final_decision(test_size=1)[0])\r\n",
        "\r\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPXeyMrr0-Yz"
      },
      "source": [
        "solver_LiDiRus = LiDiRusSolver(path='/content/combined/LiDiRus/LiDiRus.jsonl', path_valid='/content/combined/LiDiRus/LiDiRus.jsonl')\r\n",
        "solver_LiDiRus.preprocess()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh9IW4UT5PWp"
      },
      "source": [
        "test_LiDiRus = JSONL_handler('/content/combined/LiDiRus/LiDiRus.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-D-Yki3kxDE"
      },
      "source": [
        "LiDiRus_majority = [{\"idx\": idx, \"label\": str(label).lower()} for idx, label in zip(test_LiDiRus.idx, solver_LiDiRus.heuristics_all(final_decision=solver_LiDiRus.majority_class))]\r\n",
        "LiDiRus_random = [{\"idx\": idx, \"label\": str(label).lower()} for idx, label in zip(test_LiDiRus.idx, solver_LiDiRus.heuristics_all(final_decision=solver_LiDiRus.random_choice))]\r\n",
        "LiDiRus_random_b = [{\"idx\": idx, \"label\": str(label).lower()} for idx, label in zip(test_LiDiRus.idx, solver_LiDiRus.heuristics_all(final_decision=solver_LiDiRus.random_balanced_choice))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mQwrWLz5BQU"
      },
      "source": [
        "save_output(LiDiRus_majority, output_dir_heuristics_majority / \"LiDiRus.jsonl\")\r\n",
        "save_output(LiDiRus_random, output_dir_heuristics_random / \"LiDiRus.jsonl\")\r\n",
        "save_output(LiDiRus_random_b, output_dir_heuristics_rw / \"LiDiRus.jsonl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgJN35H7IECA"
      },
      "source": [
        "### RuCos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx6c3jjRIGpP"
      },
      "source": [
        "def normalize_answer(s):\r\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\r\n",
        "    def white_space_fix(text):\r\n",
        "        return ' '.join(text.split())\r\n",
        "\r\n",
        "    def remove_punc(text):\r\n",
        "        exclude = set(string.punctuation)\r\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\r\n",
        "\r\n",
        "    def lower(text):\r\n",
        "        return text.lower()\r\n",
        "\r\n",
        "    return white_space_fix(remove_punc(lower(s)))\r\n",
        "\r\n",
        "\r\n",
        "def f1_score(prediction, ground_truth):\r\n",
        "    prediction_tokens = normalize_answer(prediction).split()\r\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\r\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\r\n",
        "    num_same = sum(common.values())\r\n",
        "    if num_same == 0:\r\n",
        "        return 0\r\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\r\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\r\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\r\n",
        "    return f1\r\n",
        "\r\n",
        "\r\n",
        "def exact_match_score(prediction, ground_truth):\r\n",
        "    return normalize_answer(prediction) == normalize_answer(ground_truth)\r\n",
        "\r\n",
        "\r\n",
        "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\r\n",
        "    scores_for_ground_truths = [0]\r\n",
        "    for ground_truth in ground_truths:\r\n",
        "        score = metric_fn(prediction, ground_truth)\r\n",
        "        scores_for_ground_truths.append(score)\r\n",
        "    return max(scores_for_ground_truths)\r\n",
        "\r\n",
        "\r\n",
        "def evaluate(dataset, predictions):\r\n",
        "    f1 = exact_match = total = 0\r\n",
        "    correct_ids = []\r\n",
        "    for prediction, passage in zip(predictions, dataset):\r\n",
        "        prediction = prediction[\"label\"]\r\n",
        "        for qa in passage['qas']:\r\n",
        "            total += 1\r\n",
        "            ground_truths = list(map(lambda x: x['text'], qa.get(\"answers\", \"\")))\r\n",
        "\r\n",
        "            _exact_match = metric_max_over_ground_truths(exact_match_score, prediction, ground_truths)\r\n",
        "            if int(_exact_match) == 1:\r\n",
        "                correct_ids.append(qa['idx'])\r\n",
        "            exact_match += _exact_match\r\n",
        "\r\n",
        "            f1 += metric_max_over_ground_truths(f1_score, prediction, ground_truths)\r\n",
        "\r\n",
        "    exact_match = exact_match / total\r\n",
        "    f1 = f1 / total\r\n",
        "    return exact_match, f1\r\n",
        "\r\n",
        "\r\n",
        "def eval_RuCoS(train_path, val_path, test_path, vect):\r\n",
        "    test_score, test_pred = eval_part(test_path, vect)\r\n",
        "    return None, {\r\n",
        "        \"train\": eval_part(train_path, vect)[0],\r\n",
        "        \"val\": eval_part(val_path, vect)[0],\r\n",
        "        \"test\": test_score,\r\n",
        "        \"test_pred\": test_pred\r\n",
        "    }\r\n",
        "\r\n",
        "\r\n",
        "def eval_part(path, vect):\r\n",
        "    with jsonlines.open(path) as reader:\r\n",
        "        lines = list(reader)\r\n",
        "    preds = []\r\n",
        "    for row in lines:\r\n",
        "        pred = get_row_pred(row, vect)\r\n",
        "        preds.append({\r\n",
        "            \"idx\": row[\"idx\"],\r\n",
        "            \"label\": pred\r\n",
        "        })\r\n",
        "    return evaluate(lines, preds), preds\r\n",
        "\r\n",
        "\r\n",
        "def get_row_pred(row, vect):\r\n",
        "    res = []\r\n",
        "    words = [\r\n",
        "        row[\"passage\"][\"text\"][x[\"start\"]: x[\"end\"]]\r\n",
        "        for x in row[\"passage\"][\"entities\"]]\r\n",
        "    text  = row['passage']['text'].split()\r\n",
        "    for line in row[\"qas\"]:\r\n",
        "        line_candidates = []\r\n",
        "        _words = []\r\n",
        "        for word in words:\r\n",
        "            if word[:-2]  not in line['query'] or text.count(words[:-2]) >= 2:\r\n",
        "                _words.append(word)\r\n",
        "        if len(_words) == 0:\r\n",
        "            for word in words:\r\n",
        "                line_candidates.append(line[\"query\"].replace(\"@placeholder\", word))\r\n",
        "            pred_idx = np.random.choice(np.arange(1, len(line_candidates)),\r\n",
        "                                size=1)[0]\r\n",
        "            pred = np.array(words)[pred_idx]\r\n",
        "        elif len(_words) == 1:\r\n",
        "            pred = _words[0]\r\n",
        "        else:\r\n",
        "            for word in _words:\r\n",
        "                line_candidates.append(line[\"query\"].replace(\"@placeholder\", word))\r\n",
        "            pred_idx = np.random.choice(np.arange(1, len(line_candidates)),\r\n",
        "                                        size=1)[0]\r\n",
        "            pred = np.array(_words)[pred_idx]\r\n",
        "        res.append(pred)\r\n",
        "    return \" \".join(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZIesmGzJwDQ"
      },
      "source": [
        "train_path_RuCos = \"/content/combined/RuCoS/train.jsonl\"\r\n",
        "val_path_RuCos = \"/content/combined/RuCoS/val.jsonl\"\r\n",
        "test_path_RuCos = \"/content/combined/RuCoS/test.jsonl\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXmASW11IbRp"
      },
      "source": [
        " _, RuCoS_scores_heuristics = eval_RuCoS(train_path_RuCos, val_path_RuCos, test_path_RuCos, 'No vect')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hhy6no4JNfh"
      },
      "source": [
        "rucos_scores = RuCoS_scores_heuristics[\"test_pred\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPm6_lLhJF7z"
      },
      "source": [
        "save_output(rucos_scores, output_dir_heuristics_majority / \"RuCoS.jsonl\")\r\n",
        "save_output(rucos_scores, output_dir_heuristics_random / \"RuCoS.jsonl\")\r\n",
        "save_output(rucos_scores, output_dir_heuristics_rw / \"RuCoS.jsonl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsXUcjEXuWWL"
      },
      "source": [
        "### MuSeRC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJHkAs6wJ-8I"
      },
      "source": [
        "from MuSeRCSolver import MuSeRCSolver\r\n",
        "\r\n",
        "solver_MuSeRC = MuSeRCSolver(path='/content/combined/MuSeRC/train.jsonl',\r\n",
        "                      path_valid='/content/combined/MuSeRC/val.jsonl') # pass a dataset to get stats\r\n",
        "solver_MuSeRC.preprocess_data('/content/combined/MuSeRC/test.jsonl') # path a dataset to solve\r\n",
        "solver_MuSeRC.get_stats_MuSeRC() # collect statistics for majority and random balanced"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4GCdjPTQOD0",
        "outputId": "9a074b06-abf0-4a79-de3e-2b83c98df889"
      },
      "source": [
        "scores_muserc, _, _ = solver_MuSeRC.heuristics()\r\n",
        "scores_muserc_r, _, _ = solver_MuSeRC.heuristics('RANDOM')\r\n",
        "scores_muserc_rb, _, _ = solver_MuSeRC.heuristics('RB')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Heuristics appears for 5909 samples, 2001 of them correct\n",
            "Heuristics appears for 5909 samples, 2001 of them correct\n",
            "Heuristics appears for 5909 samples, 2001 of them correct\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXSt6RFVQuU6"
      },
      "source": [
        "save_output(scores_muserc, output_dir_heuristics_majority / \"MuSeRC.jsonl\")\r\n",
        "save_output(scores_muserc_r, output_dir_heuristics_random / \"MuSeRC.jsonl\")\r\n",
        "save_output(scores_muserc_rb, output_dir_heuristics_rw / \"MuSeRC.jsonl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m24JN9UpBnvO"
      },
      "source": [
        "### RWSD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38wQVM8BBqGh"
      },
      "source": [
        "class RWSDSolver(BaseSolverSubmit):\r\n",
        "\r\n",
        "    def __init__(self, path: str, path_test = None, path_valid=None):\r\n",
        "        self.morph = RSG_MorphAnalyzer() # PyMorphy + cashing\r\n",
        "        super(RWSDSolver, self).__init__(path, path_test, path_valid)\r\n",
        "        self.data = self.to_pandas(path_valid)     \r\n",
        "\r\n",
        "    def get_heuristics(self, length, distance, heuristic) -> dict:\r\n",
        "        \"\"\" all heuristics at once or one of them \"\"\"\r\n",
        "\r\n",
        "        heuristics = {\r\n",
        "            \"True\": {\r\n",
        "                'placeholder': False},\r\n",
        "\r\n",
        "            \"False\": {\r\n",
        "                'odd length': length % 2 == 1,\r\n",
        "                \r\n",
        "                'remainder 3': length % 4 == 3,\r\n",
        "\r\n",
        "                'remainder 2': (distance + length) % 3 != 2}\r\n",
        "                }\r\n",
        "\r\n",
        "        if heuristic != None:\r\n",
        "            # return a single heuristic only\r\n",
        "            key = list(heuristic.keys())[0]\r\n",
        "            value = heuristic[key]\r\n",
        "\r\n",
        "            return({\r\n",
        "                key: { # key = \"entailment\" or \"not_entailment\"\r\n",
        "                      value: heuristics[key][value] # \"heuristic name\": Boolean\r\n",
        "                      }\r\n",
        "                    })\r\n",
        "\r\n",
        "        return(heuristics)\r\n",
        "\r\n",
        "    def heuristics_all(self, final_decision = None, heuristic = None):\r\n",
        "        \"\"\"\r\n",
        "            apply heuristics to a dataset\r\n",
        "            To check on a single heursitic, pass\r\n",
        "                        heuristic = {\"label\": \"heuristic name\"}\r\n",
        "            to this function\r\n",
        "        \"\"\"\r\n",
        "        y_pred = []\r\n",
        "\r\n",
        "        for i, row in self.data.iterrows():\r\n",
        "            unique = self.unique(row)\r\n",
        "            distance = self.distance(row)\r\n",
        "            # length of a phrase without anticedents and proforms in tokens \r\n",
        "            length = len(unique)\r\n",
        "\r\n",
        "            heuristics = self.get_heuristics(length, distance, heuristic)\r\n",
        "\r\n",
        "            if ('True' in heuristics.keys() and\r\n",
        "                (True in list(heuristics['True'].values()))):\r\n",
        "                    y_pred.append(True)\r\n",
        "\r\n",
        "            elif ('False' in heuristics.keys() and\r\n",
        "                (True in list(heuristics['False'].values()))):\r\n",
        "                y_pred.append(False) # inserts an opposite label\r\n",
        "\r\n",
        "            else:\r\n",
        "                y_pred.append(final_decision(test_size=1)[0])\r\n",
        "\r\n",
        "        return y_pred\r\n",
        "  \r\n",
        "    def to_pandas(self, path):\r\n",
        "        \"\"\" get jsonl file content as a pandas DataFrame\"\"\"\r\n",
        "        data = []\r\n",
        "        with open(path) as f:\r\n",
        "            for line in f:\r\n",
        "                data.append(json.loads(line))\r\n",
        "\r\n",
        "        data = pd.json_normalize(data)\r\n",
        "\r\n",
        "        if 'label' not in data.columns:\r\n",
        "            data['label'] = False\r\n",
        "\r\n",
        "        return data\r\n",
        "\r\n",
        "    def unique(self, row):\r\n",
        "        \"\"\" removes span1 and span2 words from a text \"\"\"\r\n",
        "        string = row.text.replace(row['target.span1_text'],'')\r\n",
        "        string.replace(row['target.span2_text'],'')\r\n",
        "        return string\r\n",
        "\r\n",
        "\r\n",
        "    def distance(self, row):\r\n",
        "        \"\"\" calculate the distance between an anticedent and proforms in tokens\"\"\"\r\n",
        "        return row['target.span2_index'] - row['target.span1_index']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k3PYwAyB_7q"
      },
      "source": [
        "rwsd_heuristics = Heuristic_submission('RWSD', RWSDSolver)\r\n",
        "rwsd_heuristics.get_scores_random()\r\n",
        "rwsd_heuristics.get_scores_majority()\r\n",
        "rwsd_heuristics.get_scores_random_weighted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq1eLrv8dwye"
      },
      "source": [
        "# Make submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S16wnAe7eBMq"
      },
      "source": [
        "!7z a \"random_submission.zip\" $output_dir\r\n",
        "!7z a \"majority_submission.zip\" $output_dir_majority\r\n",
        "!7z a \"random_weighted_submission.zip\" $output_dir_random_weighted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnSTIme7v8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e27f0b4-8bcb-41d6-ce23-4a6c5e62210e"
      },
      "source": [
        "!7z a \"random_tfidf_submission.zip\" $output_dir_tfidf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive:\n",
            "  0M Scan \b\b\b\b\b\b\b\b\b\b          \b\b\b\b\b\b\b\b\b\b1 folder, 8 files, 1453406 bytes (1420 KiB)\n",
            "\n",
            "Creating archive: random_tfidf_submission.zip\n",
            "\n",
            "Items to compress: 9\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 99% 8 + tfidf_submission/TERRa.jsonl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Files read from disk: 8\n",
            "Archive size: 150284 bytes (147 KiB)\n",
            "Everything is Ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3Nn7m-Fk4NM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be82c33-b85f-4edd-c109-d5a0b9ac4a26"
      },
      "source": [
        "!7z a \"heuristics_random_submission.zip\" $output_dir_heuristics_random\r\n",
        "!7z a \"heuristics_majority_submission.zip\" $output_dir_heuristics_majority\r\n",
        "!7z a \"heuristics_rw_submission.zip\" $output_dir_heuristics_rw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive:\n",
            "  0M Scan \b\b\b\b\b\b\b\b\b\b          \b\b\b\b\b\b\b\b\b\b1 folder, 9 files, 1412372 bytes (1380 KiB)\n",
            "\n",
            "Creating archive: heuristics_random_submission.zip\n",
            "\n",
            "Items to compress: 10\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Files read from disk: 9\n",
            "Archive size: 136081 bytes (133 KiB)\n",
            "Everything is Ok\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive:\n",
            "  0M Scan \b\b\b\b\b\b\b\b\b\b          \b\b\b\b\b\b\b\b\b\b1 folder, 9 files, 1421995 bytes (1389 KiB)\n",
            "\n",
            "Creating archive: heuristics_majority_submission.zip\n",
            "\n",
            "Items to compress: 10\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Files read from disk: 9\n",
            "Archive size: 130632 bytes (128 KiB)\n",
            "Everything is Ok\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive:\n",
            "  0M Scan \b\b\b\b\b\b\b\b\b\b          \b\b\b\b\b\b\b\b\b\b1 folder, 9 files, 1416171 bytes (1383 KiB)\n",
            "\n",
            "Creating archive: heuristics_rw_submission.zip\n",
            "\n",
            "Items to compress: 10\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Files read from disk: 9\n",
            "Archive size: 135671 bytes (133 KiB)\n",
            "Everything is Ok\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}