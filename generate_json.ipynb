{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_json.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IwtBjRQwOEhE",
        "n9ABK_4MzNEc",
        "_oEkw7s77sXK",
        "Wq1eLrv8dwye"
      ],
      "authorship_tag": "ABX9TyMo9bmHb3izcJronmnvOVwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatiana-iazykova/2020_HACK_RUSSIANSUPERGLUE/blob/main/generate_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lPbpWjqF3t_",
        "outputId": "4a371cd9-6424-4e5b-c88a-1640664e04ea"
      },
      "source": [
        "!wget -q --show-progress \"https://raw.githubusercontent.com/tatiana-iazykova/2020_HACK_RUSSIANSUPERGLUE/main/base.py\" -O base.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rbase.py               0%[                    ]       0  --.-KB/s               \rbase.py             100%[===================>]   3.44K  --.-KB/s    in 0s      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f5wl93tIuLt"
      },
      "source": [
        "%%capture\r\n",
        "!wget https://russiansuperglue.com/tasks/download\r\n",
        "!unzip download\r\n",
        "!rm download\r\n",
        "!rm -r /content/__MACOSX\r\n",
        "!rm -r sample_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9vbghmVGEJE"
      },
      "source": [
        "from pathlib import Path\n",
        "data_dir = Path(\"combined/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9h5aNHOJu4p"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "class JSONL_handler():\r\n",
        "    \"\"\" opens a jsonl file and turns it into a necessary data structure \"\"\"\r\n",
        "    \r\n",
        "    def __init__(self, path):\r\n",
        "        self.path = path # path to jsonl file\r\n",
        "\r\n",
        "    def to_pandas(self):\r\n",
        "        \"\"\" get jsonl file content as a pandas DataFrame\"\"\"\r\n",
        "        return pd.read_json(path_or_buf=self.path, lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwtBjRQwOEhE"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeikZ_jjGN2g"
      },
      "source": [
        "output_dir = Path(\"random_submission\")\n",
        "!mkdir $output_dir"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiJ5Xvq7N9g5"
      },
      "source": [
        "output_dir_majority = Path(\"majority_submission\")\r\n",
        "!mkdir $output_dir_majority"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLUxyRPbOBQS"
      },
      "source": [
        "output_dir_random_weighted = Path(\"random_weighted_submission\")\r\n",
        "!mkdir $output_dir_random_weighted"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7wP1Ix-LIjC"
      },
      "source": [
        "from base import BaseSolverSubmit\r\n",
        "import json\r\n",
        "\r\n",
        "class Random_submission():\r\n",
        "  def __init__(self, dataset, path = None, path_valid = None, path_test = None):\r\n",
        "    self.dataset = dataset\r\n",
        "    self.path = '/content/combined/' + dataset + '/train.jsonl' if path is None else path\r\n",
        "    self.path_valid = '/content/combined/' + dataset + '/val.jsonl' if path_valid is None else path_valid\r\n",
        "    self.path_test = '/content/combined/' + dataset + '/test.jsonl' if path_test is None else path_test\r\n",
        "\r\n",
        "  def test_output(self):\r\n",
        "    test = JSONL_handler(self.path_test).to_pandas()\r\n",
        "    test_pred = [{\"idx\": idx, \"label\": str(label).lower()} for idx, label in zip(test.idx, self.scores)]\r\n",
        "    return test_pred\r\n",
        "\r\n",
        "  def get_scores_random(self):\r\n",
        "    solver = BaseSolverSubmit(path = self.path, path_valid = self.path_valid, path_test = self.path_test)\r\n",
        "    self.scores = solver.random_choice(len(solver.valid))\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir / filename)\r\n",
        "  \r\n",
        "  def get_scores_majority(self):\r\n",
        "    solver = BaseSolverSubmit(path = self.path, path_valid = self.path_valid, path_test = self.path_test)\r\n",
        "    self.scores = solver.majority_class(len(solver.valid))\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir_majority / filename)\r\n",
        "\r\n",
        "  def get_scores_random_weighted(self):\r\n",
        "    solver = BaseSolverSubmit(path = self.path, path_valid = self.path_valid, path_test = self.path_test)\r\n",
        "    self.scores = solver.random_balanced_choice(len(solver.valid))\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir_random_weighted / filename)\r\n",
        "  \r\n",
        "  def save_output(self, data, path):\r\n",
        "    with open(path, mode=\"w\") as file:\r\n",
        "        for line in sorted(data, key=lambda x: int(x.get(\"idx\"))):\r\n",
        "            line[\"idx\"] = int(line[\"idx\"])\r\n",
        "            file.write(f\"{json.dumps(line, ensure_ascii=False)}\\n\")"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxRpQnEwRB3V"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThXAIyUtOSQa"
      },
      "source": [
        "### DaNetQA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1WEnl_hLCpj"
      },
      "source": [
        "random = Random_submission('DaNetQA')\r\n",
        "random.get_scores_random()"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRYjjA70PpM9"
      },
      "source": [
        "majority = Random_submission('DaNetQA')\r\n",
        "majority.get_scores_majority()"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym8S_etCQFtZ"
      },
      "source": [
        "random_w = Random_submission('DaNetQA')\r\n",
        "random_w.get_scores_random_weighted()"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4T64U3WOY8v"
      },
      "source": [
        "### RCB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03jeA6qjOhvP"
      },
      "source": [
        "random_RCB = Random_submission('RCB')\r\n",
        "random_RCB.get_scores_random()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjsJVqRYPsbq"
      },
      "source": [
        "majority_RCB = Random_submission('RCB')\r\n",
        "majority_RCB.get_scores_majority()"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uDJuEKNQORD"
      },
      "source": [
        "random_w_RCB = Random_submission('RCB')\r\n",
        "random_w_RCB.get_scores_random_weighted()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TinpaoG7Omcc"
      },
      "source": [
        "### PARus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkIhBzEOOpwy"
      },
      "source": [
        "random_PARus = Random_submission('PARus')\r\n",
        "random_PARus.get_scores_random()"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAswUVeEPxni"
      },
      "source": [
        "majority_PARus = Random_submission('PARus')\r\n",
        "majority_PARus.get_scores_majority()"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoYJtkAyQTrg"
      },
      "source": [
        "random_w_PARus = Random_submission('PARus')\r\n",
        "random_w_PARus.get_scores_random_weighted()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osXHWsymOwyw"
      },
      "source": [
        "### TERRa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wAPpm7bO2L2"
      },
      "source": [
        "random_TERRa = Random_submission('TERRa')\r\n",
        "random_TERRa.get_scores_random()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWfro-_xPyci"
      },
      "source": [
        "majority_TERRa = Random_submission('TERRa')\r\n",
        "majority_TERRa.get_scores_majority()"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjHu9xsAQZLI"
      },
      "source": [
        "random_w_TERRa = Random_submission('TERRa')\r\n",
        "random_w_TERRa.get_scores_random_weighted()"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VjhRf8cPGAC"
      },
      "source": [
        "### RUSSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7ztK2mLPKS6"
      },
      "source": [
        "random_RUSSE = Random_submission('RUSSE')\r\n",
        "random_RUSSE.get_scores_random()"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmW6tApJP24g"
      },
      "source": [
        "majority_RUSSE = Random_submission('RUSSE')\r\n",
        "majority_RUSSE.get_scores_majority()"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_omu7Y3QXyS"
      },
      "source": [
        "random_w_RUSSE = Random_submission('RUSSE')\r\n",
        "random_w_RUSSE.get_scores_random_weighted()"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNBcUdxmlt1S"
      },
      "source": [
        "### RWSD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNYkV3sFltHo"
      },
      "source": [
        "random_RWSD = Random_submission('RWSD')\r\n",
        "random_RWSD.get_scores_random()"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJPOljV2P6mK"
      },
      "source": [
        "majority_RWSD = Random_submission('RWSD')\r\n",
        "majority_RWSD.get_scores_majority()"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXVkLbdVQi2V"
      },
      "source": [
        "random_w_RWSD = Random_submission('RWSD')\r\n",
        "random_w_RWSD.get_scores_random_weighted()"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRp4kZ2_r-5Q"
      },
      "source": [
        "### LidiRus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2COVBIBsCUS"
      },
      "source": [
        "random_LiDiRus = Random_submission('LiDiRus', path = '/content/combined/TERRa/train.jsonl', path_valid='/content/combined/TERRa/val.jsonl',\r\n",
        "                                   path_test = '/content/combined/LiDiRus/LiDiRus.jsonl')\r\n",
        "random_LiDiRus.get_scores_random()"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yDTfhUOP-g_"
      },
      "source": [
        "majority_LiDiRus = Random_submission('LiDiRus', path = '/content/combined/TERRa/train.jsonl', path_valid='/content/combined/TERRa/val.jsonl',\r\n",
        "                                   path_test = '/content/combined/LiDiRus/LiDiRus.jsonl')\r\n",
        "majority_LiDiRus.get_scores_majority()"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh5_ilxBQmQz"
      },
      "source": [
        "random_w_LiDiRus = Random_submission('LiDiRus', path = '/content/combined/TERRa/train.jsonl', path_valid='/content/combined/TERRa/val.jsonl',\r\n",
        "                                   path_test = '/content/combined/LiDiRus/LiDiRus.jsonl')\r\n",
        "random_w_LiDiRus.get_scores_random_weighted()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9ABK_4MzNEc"
      },
      "source": [
        "# Optimised Tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iVCypzz3Gu8"
      },
      "source": [
        "output_dir_tfidf = Path(\"tfidf_submission\")\r\n",
        "!mkdir $output_dir_tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2nmmekl1Pmn"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.preprocessing import FunctionTransformer\r\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1BH--9D0JS1"
      },
      "source": [
        "def unite(path1, path2):\r\n",
        "  df = JSONL_handler(path1).to_pandas()\r\n",
        "  df1 = JSONL_handler(path2).to_pandas()\r\n",
        "  return pd.concat([df, df1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEgnk8p61wiF"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "class Tfidf_Submisssion():\r\n",
        "  \r\n",
        "  def __init__(self, test, predictions, filename):\r\n",
        "    self.test = test\r\n",
        "    self.predictions = predictions\r\n",
        "    self.filename = filename + '.jsonl'\r\n",
        "\r\n",
        "  def test_output(self):\r\n",
        "    test_pred = [{\"idx\": idx, \"label\": str(label).lower()} for idx, label in zip(self.test.idx, self.predictions)]\r\n",
        "    self.save_output(test_pred, output_dir_tfidf / self.filename)\r\n",
        "\r\n",
        "  def save_output(self, data, path):\r\n",
        "    with open(path, mode=\"w\") as file:\r\n",
        "        for line in sorted(data, key=lambda x: int(x.get(\"idx\"))):\r\n",
        "            line[\"idx\"] = int(line[\"idx\"])\r\n",
        "            file.write(f\"{json.dumps(line, ensure_ascii=False)}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oEkw7s77sXK"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNQmcII0z1Ej"
      },
      "source": [
        "### RCB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVq5FEnUz4s8"
      },
      "source": [
        "RCB_train = unite('/content/combined/RCB/train.jsonl', '/content/combined/RCB/val.jsonl')\r\n",
        "RCB_test = JSONL_handler('/content/combined/RCB/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raUj6PU0zSn_"
      },
      "source": [
        "steps_RCB = [('tfidf', TfidfVectorizer(analyzer='word', max_features=10000)),\r\n",
        "          ('func', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)),\r\n",
        "         ('sgd', SGDClassifier(loss=\"log\", n_jobs=-1, alpha=0.00001, class_weight='balanced', random_state=42))]\r\n",
        "\r\n",
        "pipeline_RCB = Pipeline(steps_RCB)\r\n",
        "\r\n",
        "pipeline_RCB.fit(RCB_train.hypothesis, RCB_train.label)\r\n",
        "y_pred_RCB = pipeline_RCB.predict(RCB_test.hypothesis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsEEsUjf2Wtt"
      },
      "source": [
        "tfidf_rcb = Tfidf_Submisssion(RCB_test, y_pred_RCB, 'RCB')\r\n",
        "tfidf_rcb.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt16TWzM5bR3"
      },
      "source": [
        "### TERRa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdr7HuLi56CD"
      },
      "source": [
        "TERRa_train = unite('/content/combined/TERRa/train.jsonl', '/content/combined/TERRa/val.jsonl')\r\n",
        "TERRa_test = JSONL_handler('/content/combined/TERRa/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi87kVdr5dxY"
      },
      "source": [
        "steps_TERRa = [('countvect', CountVectorizer(min_df=15, max_df=0.4, lowercase=True, analyzer ='char_wb', decode_error = 'ignore', ngram_range = (2, 4))),\r\n",
        "         ('sgd', SGDClassifier(alpha = 1e-08, loss=\"log\", n_jobs=-1, class_weight='balanced', random_state=42))]\r\n",
        "\r\n",
        "pipeline_TERRa = Pipeline(steps_TERRa)\r\n",
        "\r\n",
        "pipeline_TERRa.fit(TERRa_train.hypothesis, TERRa_train.label)\r\n",
        "y_pred_TERRa = pipeline_TERRa.predict(TERRa_test.hypothesis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgfqX79x5_zE"
      },
      "source": [
        "tfidf_terra = Tfidf_Submisssion(TERRa_test, y_pred_TERRa, 'TERRa')\r\n",
        "tfidf_terra.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlsZGLAu6U1C"
      },
      "source": [
        "### DaNetQA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjj-SXgl6XpT"
      },
      "source": [
        "DaNetQA_train = unite('/content/combined/DaNetQA/train.jsonl', '/content/combined/DaNetQA/val.jsonl')\r\n",
        "DaNetQA_test = JSONL_handler('/content/combined/DaNetQA/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ90YD9a6aBY"
      },
      "source": [
        "steps_DaNetQA = [('vectorizer', TfidfVectorizer()),\r\n",
        "              ('sgd', SGDClassifier(loss=\"log\", n_jobs=-1, alpha=0.15, class_weight='balanced', random_state=42))]\r\n",
        "\r\n",
        "pipeline_DaNetQA = Pipeline(steps_DaNetQA)\r\n",
        "\r\n",
        "pipeline_DaNetQA.fit(DaNetQA_train.question, DaNetQA_train.label)\r\n",
        "y_pred_DaNetQA = pipeline_DaNetQA.predict(DaNetQA_test.question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3mG5sHj7TdO"
      },
      "source": [
        "tfidf_danetqa = Tfidf_Submisssion(DaNetQA_test, y_pred_DaNetQA, 'DaNetQa')\r\n",
        "tfidf_danetqa.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp4MWtzPOIUq"
      },
      "source": [
        "### RUSSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Z6EI5WOC_j"
      },
      "source": [
        "RUSSE_train = unite('/content/combined/RUSSE/train.jsonl', '/content/combined/RUSSE/val.jsonl')\r\n",
        "RUSSE_test = JSONL_handler('/content/combined/RUSSE/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgxB7dsrOSfc"
      },
      "source": [
        "def build_feature_RUSSE(row):\r\n",
        "    sentence1 = row[\"sentence1\"].strip()\r\n",
        "    sentence2 = row[\"sentence2\"].strip()\r\n",
        "    word = row[\"word\"].strip()\r\n",
        "    res = f\"{sentence1} {sentence2} {word}\"\r\n",
        "    return res\r\n",
        "\r\n",
        "train_concat = []\r\n",
        "for i, row in RUSSE_train.iterrows():\r\n",
        "    train_concat.append(build_feature_RUSSE(row))\r\n",
        "RUSSE_train['concatenated'] = train_concat\r\n",
        "\r\n",
        "valid_concat = []\r\n",
        "for i, row in RUSSE_test.iterrows():\r\n",
        "    valid_concat.append(build_feature_RUSSE(row))\r\n",
        "RUSSE_test['concatenated'] =  valid_concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BGlbWXjOg9Y"
      },
      "source": [
        "steps_RUSSE = [('tfidf', TfidfVectorizer(analyzer = 'word', max_df = 0.6, min_df= 0.001, ngram_range =  (1,2))),\r\n",
        "         ('logreg', LogisticRegression(C = 1.01, class_weight='balanced'))]\r\n",
        "\r\n",
        "pipeline_RUSSE = Pipeline(steps_RUSSE)\r\n",
        "\r\n",
        "pipeline_RUSSE.fit(RUSSE_train.concatenated, RUSSE_train.label)\r\n",
        "y_pred_RUSSE = pipeline_RUSSE.predict(RUSSE_test.concatenated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn4d1QvzPJBQ"
      },
      "source": [
        "tfidf_russe = Tfidf_Submisssion(RUSSE_test, y_pred_RUSSE, 'RUSSE')\r\n",
        "tfidf_russe.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmTCOY9tSLHd"
      },
      "source": [
        "### PARus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7QvfQzJSRYD"
      },
      "source": [
        "PARus_train = unite('/content/combined/PARus/train.jsonl', '/content/combined/PARus/val.jsonl')\r\n",
        "PARus_test = JSONL_handler('/content/combined/PARus/test.jsonl').to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3DMGV2OSKiM"
      },
      "source": [
        "def build_feature_PARus(row):\r\n",
        "    premise = str(row[\"premise\"]).strip()\r\n",
        "    choice1 = row[\"choice1\"]\r\n",
        "    choice2 = row[\"choice2\"]\r\n",
        "    label = row.get(\"label\")\r\n",
        "    question = \"Что было ПРИЧИНОЙ этого?\" if row[\"question\"] == \"cause\" else \"Что случилось в РЕЗУЛЬТАТЕ?\"\r\n",
        "    res = f\"{premise} {question} {choice1} {choice2}\"\r\n",
        "    return res\r\n",
        "\r\n",
        "\r\n",
        "train_concat = []\r\n",
        "for i, row in PARus_train.iterrows():\r\n",
        "    train_concat.append(build_feature_PARus(row))\r\n",
        "PARus_train['concatenated'] = train_concat\r\n",
        "\r\n",
        "valid_concat = []\r\n",
        "for i, row in PARus_test.iterrows():\r\n",
        "    valid_concat.append(build_feature_PARus(row))\r\n",
        "PARus_test['concatenated'] =  valid_concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_5yCz-aSdPw"
      },
      "source": [
        "steps_PARus = [('tfidf', TfidfVectorizer(analyzer= 'word', max_df= 0.6, min_df= 0.04, ngram_range= (1, 2))),\r\n",
        "         ('logreg', LogisticRegression(C = 1e-10, class_weight='balanced'))]\r\n",
        "\r\n",
        "pipeline_PARus = Pipeline(steps_PARus)\r\n",
        "\r\n",
        "pipeline_PARus.fit(PARus_train.concatenated, PARus_train.label)\r\n",
        "y_pred_PARus = pipeline_PARus.predict(PARus_test.concatenated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeXsS7HKS94r"
      },
      "source": [
        "tfidf_parus = Tfidf_Submisssion(PARus_test, y_pred_PARus, 'PARus')\r\n",
        "tfidf_parus.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nn08m3ATJMW"
      },
      "source": [
        "### LiDiRus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD2-ovnrTL60"
      },
      "source": [
        "LiDiRus_train = unite('/content/combined/TERRa/train.jsonl', '/content/combined/TERRa/val.jsonl').assign(merged=lambda x: x.premise + \"\\n\" + x.hypothesis)\r\n",
        "LiDiRus_test = JSONL_handler('/content/combined/LiDiRus/LiDiRus.jsonl').to_pandas().assign(merged=lambda x: x.sentence1 + \"\\n\" + x.sentence2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AhpFcZUVMMF"
      },
      "source": [
        "steps_LiDiRus = [('tfidf', TfidfVectorizer(analyzer= 'char_wb', max_df= 0.6, min_df=0.091, ngram_range = (1, 1))),\r\n",
        "         ('logreg', LogisticRegression(C = 1.01, class_weight='balanced'))]\r\n",
        "\r\n",
        "pipeline_LiDiRus = Pipeline(steps_LiDiRus)\r\n",
        "\r\n",
        "pipeline_LiDiRus.fit(LiDiRus_train.merged, LiDiRus_train.label)\r\n",
        "y_pred_LiDiRus = pipeline_LiDiRus.predict(LiDiRus_test.merged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBGa0LaKWHar"
      },
      "source": [
        "tfidf_lidirus = Tfidf_Submisssion(LiDiRus_test, y_pred_LiDiRus, 'LiDiRus')\r\n",
        "tfidf_lidirus.test_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4n1h3Kje-1O"
      },
      "source": [
        "# Heuristics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eudc_bvWfFOg"
      },
      "source": [
        "output_dir_heuristics_random = Path(\"heuristics_random_submission\")\r\n",
        "!mkdir $output_dir_heuristics_random"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER5L92uRnmqJ"
      },
      "source": [
        "output_dir_heuristics_majority = Path(\"heuristics_majority_submission\")\r\n",
        "!mkdir $output_dir_heuristics_majority"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-uURRZ1nrb5"
      },
      "source": [
        "output_dir_heuristics_rw = Path(\"heuristics_rw_submission\")\r\n",
        "!mkdir $output_dir_heuristics_rw"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkrdG2dCfIOA"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "class Heuristic_submission():\r\n",
        "  def __init__(self, dataset, solver, path = None, path_valid = None, path_test = None):\r\n",
        "    self.dataset = dataset\r\n",
        "    self.path = '/content/combined/' + dataset + '/train.jsonl' if path is None else path\r\n",
        "    self.path_valid = '/content/combined/' + dataset + '/val.jsonl' if path_valid is None else path_valid\r\n",
        "    self.path_test = '/content/combined/' + dataset + '/test.jsonl' if path_test is None else path_test\r\n",
        "    self.solver = solver(path=self.path, path_valid= self.path_valid, path_test = self.path_test)\r\n",
        "\r\n",
        "  def test_output(self):\r\n",
        "    test = JSONL_handler(self.path_test).to_pandas()\r\n",
        "    test_pred = [{\"idx\": idx, \"label\": str(label).lower()} for idx, label in zip(test.idx, self.scores)]\r\n",
        "    return test_pred\r\n",
        "\r\n",
        "  def get_scores_random(self):\r\n",
        "    self.scores = self.solver.heuristics_all(final_desicion=self.solver.random_choice)\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir_heuristics_random / filename)\r\n",
        "  \r\n",
        "  def get_scores_majority(self):\r\n",
        "    self.scores = self.solver.heuristics_all(final_desicion=self.solver.majority_class)\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir_heuristics_majority / filename)\r\n",
        "\r\n",
        "  def get_scores_random_weighted(self):\r\n",
        "    self.scores = self.solver.heuristics_all(final_desicion=self.solver.random_balanced_choice)\r\n",
        "    filename = self.dataset + \".jsonl\"\r\n",
        "    self.save_output(self.test_output(), output_dir_heuristics_rw / filename)\r\n",
        "  \r\n",
        "  def save_output(self, data, path):\r\n",
        "    with open(path, mode=\"w\") as file:\r\n",
        "        for line in sorted(data, key=lambda x: int(x.get(\"idx\"))):\r\n",
        "            line[\"idx\"] = int(line[\"idx\"])\r\n",
        "            file.write(f\"{json.dumps(line, ensure_ascii=False)}\\n\")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGYEsphefzxH"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6whDZkEsf2Bb"
      },
      "source": [
        "### TERRa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ck9wn9ViCGQ"
      },
      "source": [
        "%%capture\r\n",
        "!pip install pymorphy2"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHI10Lurf5L2"
      },
      "source": [
        "import pymorphy2\r\n",
        "import re\r\n",
        "from pymorphy2 import MorphAnalyzer\r\n",
        "import nltk\r\n",
        "from functools import lru_cache\r\n",
        "from base import BaseSolverSubmit\r\n",
        "\r\n",
        "m = MorphAnalyzer()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ-vKqCMf9Kx"
      },
      "source": [
        "class TERRaSolver(BaseSolverSubmit):\r\n",
        "   \r\n",
        "    def __init__(self, path: str, path_valid=None, path_test=None):\r\n",
        "        super(TERRaSolver, self).__init__(path, path_valid, path_test)\r\n",
        "   \r\n",
        "    def preprocess(self, columns):\r\n",
        "      for column in columns:\r\n",
        "        self.train[f\"{column}_lemmas\"] = self.train[column].apply(self.clean_text)\r\n",
        "        self.valid[f\"{column}_lemmas\"] = self.valid[column].apply(self.clean_text)\r\n",
        " \r\n",
        "    def words_only(self, text):\r\n",
        "      rg = re.compile(\"[А-Яа-яA-z]+\")\r\n",
        "      try:\r\n",
        "        return rg.findall(text.lower())\r\n",
        "      except:\r\n",
        "        return []\r\n",
        "\r\n",
        "    @lru_cache(maxsize=128)\r\n",
        "    def lemmatize_word(self, token, pymorphy=m):\r\n",
        "      return pymorphy.parse(token)[0].normal_form\r\n",
        "\r\n",
        "    def lemmatize_text(self, text):\r\n",
        "      return [self.lemmatize_word(w) for w in text]\r\n",
        "\r\n",
        "    def clean_text(self, text):\r\n",
        "      tokens = self.words_only(text)\r\n",
        "      lemmas = self.lemmatize_text(tokens)  \r\n",
        "      return lemmas\r\n",
        "    \r\n",
        "    def heuristics_all(self, final_desicion=None):\r\n",
        "        y_pred = []\r\n",
        "        self.preprocess(columns=['premise', \"hypothesis\"])\r\n",
        "\r\n",
        "        for i, row in self.valid.iterrows():\r\n",
        "          \r\n",
        "          hyp = row.hypothesis.lower()\r\n",
        "          hyp_lem = set(row['hypothesis_lemmas'])\r\n",
        "          prem_lem = set(row['premise_lemmas'])\r\n",
        "          indic_non_ent = set(['только', 'мужчина'])\r\n",
        "\r\n",
        "          if hyp in row['premise'].lower():\r\n",
        "             y_pred.append('entailment')\r\n",
        "          elif len(prem_lem & hyp_lem)/len(hyp_lem) <= 1/3 or len(row['premise'].split()) < 29 or len(indic_non_ent & hyp_lem) > 0:\r\n",
        "            y_pred.append('not_entailment')\r\n",
        "          elif len(prem_lem & hyp_lem)/len(hyp_lem) == 0.75 or len(prem_lem & hyp_lem)/len(hyp_lem) == 1 or len(prem_lem & hyp_lem)/len(hyp_lem) == 2/3:\r\n",
        "            y_pred.append('entailment')\r\n",
        "          elif len(row['premise'].split()) > 32:\r\n",
        "            y_pred.append('entailment')\r\n",
        "          else:\r\n",
        "            y_pred.append(final_desicion(test_size=1)[0])\r\n",
        "        \r\n",
        "        return y_pred"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVREJMh1pD-g"
      },
      "source": [
        "solver = TERRaSolver(path='/content/combined/TERRa/train.jsonl',\r\n",
        "                     path_valid='/content/combined/TERRa/val.jsonl',\r\n",
        "                     path_test = '/content/combined/TERRa/test.jsonl')"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hIsqZbHvsNhM",
        "outputId": "8f300794-6773-4494-dd0b-be93252bb722"
      },
      "source": [
        "solver.train"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "      <th>idx</th>\n",
              "      <th>premise_lemmas</th>\n",
              "      <th>hypothesis_lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Женщину доставили в больницу, за ее жизнь сейч...</td>\n",
              "      <td>Женщину спасают врачи.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>0</td>\n",
              "      <td>[женщина, доставить, в, больница, за, она, жиз...</td>\n",
              "      <td>[женщина, спасать, врач]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Он проводит невидимую грань между настоящим и ...</td>\n",
              "      <td>В эти минуты все мы подводим друг друга.</td>\n",
              "      <td>not_entailment</td>\n",
              "      <td>1</td>\n",
              "      <td>[он, проводить, невидимый, грань, между, насто...</td>\n",
              "      <td>[в, этот, минута, всё, мы, подводить, друг, друг]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Мужчина рассказал: детская коляска, принадлежа...</td>\n",
              "      <td>Сосед часто крадет детские коляски ради денег.</td>\n",
              "      <td>not_entailment</td>\n",
              "      <td>2</td>\n",
              "      <td>[мужчина, рассказать, детский, коляска, принад...</td>\n",
              "      <td>[сосед, часто, красть, детский, коляска, ради,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Я просто об этом даже не думаю, потому что есл...</td>\n",
              "      <td>Спрятаться не удастся.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3</td>\n",
              "      <td>[я, просто, о, это, даже, не, думать, потому, ...</td>\n",
              "      <td>[спрятаться, не, удаться]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>В ходе проверки нашли дома с наледью и сосульк...</td>\n",
              "      <td>Все сосульки с крыш были сбиты.</td>\n",
              "      <td>not_entailment</td>\n",
              "      <td>4</td>\n",
              "      <td>[в, ход, проверка, наслать, дом, с, наледь, и,...</td>\n",
              "      <td>[всё, сосулька, с, крыша, быть, сбить]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3193</th>\n",
              "      <td>По мнению экспертов, большинство курильщиков н...</td>\n",
              "      <td>Эксперты сомневаются в способности курильщиков...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3193</td>\n",
              "      <td>[по, мнение, эксперт, большинство, курильщик, ...</td>\n",
              "      <td>[эксперт, сомневаться, в, способность, курильщ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3194</th>\n",
              "      <td>Как рассказали в краевой полиции, еще летом пр...</td>\n",
              "      <td>Ради денег молодой человек регистрировал у себ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3194</td>\n",
              "      <td>[как, рассказать, в, краевой, полиция, ещё, ле...</td>\n",
              "      <td>[ради, деньга, молодой, человек, регистрироват...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3195</th>\n",
              "      <td>Московскому институту теплотехники (МИТ) сейча...</td>\n",
              "      <td>Подольский электромеханический завод столкнулс...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3195</td>\n",
              "      <td>[московский, институт, теплотехник, мит, сейча...</td>\n",
              "      <td>[подольский, электромеханический, завод, столк...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3196</th>\n",
              "      <td>После мужчина убегал, а сумки вместе с содержи...</td>\n",
              "      <td>Мужчина выкидывал сумки и деньги.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3196</td>\n",
              "      <td>[после, мужчина, убегать, а, сумка, вместе, с,...</td>\n",
              "      <td>[мужчина, выкидывать, сумка, и, деньга]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>\"Кроме того, на корабле, по словам Лаврова, на...</td>\n",
              "      <td>Лавров назвал британскую страховую систему нен...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3197</td>\n",
              "      <td>[кроме, тот, на, корабль, по, слово, лавров, н...</td>\n",
              "      <td>[лавров, назвать, британский, страховой, систе...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5814 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                premise  ...                                  hypothesis_lemmas\n",
              "0     Женщину доставили в больницу, за ее жизнь сейч...  ...                           [женщина, спасать, врач]\n",
              "1     Он проводит невидимую грань между настоящим и ...  ...  [в, этот, минута, всё, мы, подводить, друг, друг]\n",
              "2     Мужчина рассказал: детская коляска, принадлежа...  ...  [сосед, часто, красть, детский, коляска, ради,...\n",
              "3     Я просто об этом даже не думаю, потому что есл...  ...                          [спрятаться, не, удаться]\n",
              "4     В ходе проверки нашли дома с наледью и сосульк...  ...             [всё, сосулька, с, крыша, быть, сбить]\n",
              "...                                                 ...  ...                                                ...\n",
              "3193  По мнению экспертов, большинство курильщиков н...  ...  [эксперт, сомневаться, в, способность, курильщ...\n",
              "3194  Как рассказали в краевой полиции, еще летом пр...  ...  [ради, деньга, молодой, человек, регистрироват...\n",
              "3195  Московскому институту теплотехники (МИТ) сейча...  ...  [подольский, электромеханический, завод, столк...\n",
              "3196  После мужчина убегал, а сумки вместе с содержи...  ...            [мужчина, выкидывать, сумка, и, деньга]\n",
              "3197  \"Кроме того, на корабле, по словам Лаврова, на...  ...  [лавров, назвать, британский, страховой, систе...\n",
              "\n",
              "[5814 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdHGDcCRrukY"
      },
      "source": [
        "solver.heuristics_all(final_desicion=solver.random_balanced_choice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq1eLrv8dwye"
      },
      "source": [
        "# Make submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S16wnAe7eBMq"
      },
      "source": [
        "!7z a \"random_submission.zip\" $output_dir\r\n",
        "!7z a \"majority_submission.zip\" $output_dir_majority\r\n",
        "!7z a \"random_weighted_submission.zip\" $output_dir_random_weighted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnSTIme7v8K"
      },
      "source": [
        "!7z a \"random_weighted_submission.zip\" $output_dir_tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_yfdDTidf4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5587d4-cf27-49d1-d353-2ea79589f9bb"
      },
      "source": [
        "!7z a \"random_weighted_submission.zip\" $output_dir_random_weighted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive:\n",
            "  0M Scan \b\b\b\b\b\b\b\b\b\b          \b\b\b\b\b\b\b\b\b\b1 folder, 7 files, 828435 bytes (810 KiB)\n",
            "\n",
            "Creating archive: random_weighted_submission.zip\n",
            "\n",
            "Items to compress: 8\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Files read from disk: 7\n",
            "Archive size: 54668 bytes (54 KiB)\n",
            "Everything is Ok\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}